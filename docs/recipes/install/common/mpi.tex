For MPI development and runtime support, \OHPC{} provides pre-packaged builds
for a variety of MPI families and transport layers. Currently available options
and their applicability to various network transports are summarized in
Table~\ref{table:mpi}.  The command that follows installs a starting set of MPI
families that are compatible with ethernet fabrics. 

\iftoggleverb{isx86}
% x86_64

\begin{table}[h]
\caption{Available MPI variants} \label{table:mpi}
\centering
\begin{tabular}{@{\hspace*{0.2cm}} *5l @{}}    \toprule
                                  & Ethernet (TCP)                 & \InfiniBand{}                  & \IntelR{} Omni-Path            \\ \midrule
\rowcolor{black!10} MPICH         & \multicolumn{1}{c}{\checkmark} &                                &                                \\
MVAPICH2                          &                                & \multicolumn{1}{c}{\checkmark} &                                \\
\rowcolor{black!10} MVAPICH2 (psm2) &                              &                                & \multicolumn{1}{c}{\checkmark} \\
OpenMPI                           & \multicolumn{1}{c}{\checkmark} & \multicolumn{1}{c}{\checkmark} & \multicolumn{1}{c}{\checkmark} \\
\rowcolor{black!10} OpenMPI (PMIx) & \multicolumn{1}{c}{\checkmark} & \multicolumn{1}{c}{\checkmark} & \multicolumn{1}{c}{\checkmark} \\ \bottomrule
\end{tabular}
\end{table}

\else
% aarch64

\begin{table}[h]
\caption{Available MPI builds} \label{table:mpi}
\centering
\begin{tabular}{@{\hspace*{0.2cm}} *5l @{}}    \toprule
                                  & Ethernet (TCP)                 & \InfiniBand{}                              \\ \midrule
\rowcolor{black!10} MPICH         & \multicolumn{1}{c}{\checkmark} &                                            \\
\rowcolor{black!10} OpenMPI                           & \multicolumn{1}{c}{\checkmark} & \multicolumn{1}{c}{\checkmark} \\
\end{tabular}
\end{table}

\fi

% begin_ohpc_run
% ohpc_comment_header Install MPI Stacks \ref{sec:mpi}
% ohpc_command if [[ ${enable_mpi_defaults} -eq 1 && ${enable_pmix} -eq 0 ]];then
% ohpc_indent 5
\begin{lstlisting}[language=bash]
[sms](*\#*) (*\install*) openmpi3-gnu8-ohpc mpich-gnu8-ohpc
\end{lstlisting}
% ohpc_indent 0
% ohpc_command elif [[ ${enable_mpi_defaults} -eq 1 && ${enable_pmix} -eq 1 ]];then
% ohpc_indent 5
% ohpc_command (*\install*) openmpi3-pmix-slurm-gnu8-ohpc mpich-gnu8-ohpc
% ohpc_indent 0
% ohpc_command fi

If your system includes \InfiniBand{} and you enabled underlying support in
\S\ref{sec:add_ofed} and \S\ref{sec:addl_customizations}, an additional
MVAPICH2 family is available for use:

% begin_ohpc_run
% ohpc_validation_newline
% ohpc_command if [[ ${enable_ib} -eq 1 ]];then
% ohpc_indent 5
\begin{lstlisting}[language=bash]
[sms](*\#*) (*\install*) mvapich2-gnu8-ohpc
\end{lstlisting}
% ohpc_indent 0
% ohpc_command fi
% end_ohpc_run

Alternatively, if your system includes \IntelR{} \OmniPath{}, use the (\texttt{psm2})
variant of MVAPICH2 instead:

% begin_ohpc_run
% ohpc_command if [[ ${enable_opa} -eq 1 ]];then
% ohpc_indent 5
\begin{lstlisting}[language=bash]
[sms](*\#*) (*\install*) mvapich2-psm2-gnu8-ohpc
\end{lstlisting}
% ohpc_indent 0
% ohpc_command fi
% end_ohpc_run

An additional OpenMPI build variant is listed in Table~\ref{table:mpi} which
enables \href{https://pmix.github.io/pmix/}{\color{blue}{PMIx}} job launch
support for use with \SLURM{}. This optional variant is
available as \texttt{openmpi3-pmix-slurm-gnu8-ohpc}.
